#  NLP - Analyse de Sentiments

##  Objectif

Ce projet a pour but de dÃ©velopper un systÃ¨me de **classification des sentiments** Ã  partir de **posts issus des rÃ©seaux sociaux**, en utilisant des **modÃ¨les NLP** basÃ©s sur BERT.

L'objectif est de dÃ©terminer si un post est :

- **Positif** : exprime une opinion favorable, de la joie ou de la satisfaction.
- **NÃ©gatif** : reflÃ¨te une critique, une insatisfaction ou une Ã©motion dÃ©sagrÃ©able.

---

##  Dataset

Nous utilisons le dataset **[Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140)** :
-  **1,6 million de tweets annotÃ©s** selon leur polaritÃ© (positif ou nÃ©gatif)

###  Instructions pour l'installation :

1. TÃ©lÃ©charger le dataset depuis Kaggle.
2. Le renommer en `finetuning.csv`.
3. ExÃ©cuter le script de prÃ©paration des donnÃ©es :
   ```bash
   python datapreparation.py

Ce script effectue les Ã©tapes suivantes :

    Nettoyage des tweets (URLs, mentions, hashtagsâ€¦)

    Division des donnÃ©es en jeu d'entraÃ®nement, de validation et de test

 ModÃ¨les entraÃ®nÃ©s
1. distilbert-base-uncased-finetuned-sst-2-english

    ModÃ¨le prÃ©-entraÃ®nÃ© disponible via HuggingFace, fine-tunÃ© sur SST-2

    ExÃ©cution directe sur les donnÃ©es de test :

    python finetuned.py

     Accuracy obtenue : 72%

2.  bert-base-uncased + MLP personnalisÃ©

    Ajout de 3 couches fully-connected aprÃ¨s BERT (architecture BertClassifier)

    Pour entraÃ®ner le modÃ¨le :

python deeptuning.py

Pour Ã©valuer sur les donnÃ©es de test :

    python resultdeeptuning.py

     Accuracy obtenue : 78%

3. distilbert-base-uncased + couche linÃ©aire

    Fine-tuning de DistilBERT avec une couche Linear Ã  2 sorties

    Meilleure performance globale

    EntraÃ®nement :

python finetuning.py

Le modÃ¨le est sauvegardÃ© dans le dossier treatment/.

Ã‰valuation :

    python resultfinetuning.py

     Accuracy obtenue : 82%

 Scraping & Analyse Reddit

Pour scraper des publications Reddit et les analyser avec le modÃ¨le DistilBERT :

docker compose up -d --build

Cela lance un environnement Docker qui s'occupe de :

    Scraper les posts via l'API Reddit

    Filtrer les contenus en anglais

    PrÃ©dire le sentiment de chaque post


    Structure du projet (optionnel)

â”œâ”€â”€ datapreparation.py
â”œâ”€â”€ model_deep_fine/
â”‚ â””â”€â”€ best_bert_classifier.pt
â”œâ”€â”€ deeptuning.py
â”œâ”€â”€ resultdeeptuning.py
â”œâ”€â”€ finetuning.py
â”œâ”€â”€ resultfinetuning.py
â”œâ”€â”€ finetuned.py
â”œâ”€â”€ treatment/
â”‚ â”œâ”€â”€ best_model.pt
â”‚ â”œâ”€â”€ config.json
â”‚ â”œâ”€â”€ model.safetensors
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â””â”€â”€ script.py
â”œâ”€â”€ finetuning.csv
â”œâ”€â”€ dockercompose.yml
â””â”€â”€ README.md


 Technologies utilisÃ©es

    Python 3.10

    PyTorch

    HuggingFace Transformers

    scikit-learn

    pandas, numpy, tqdm

    Docker


## ğŸ’¡ En cas de problÃ¨me

Si vous rencontrez des erreurs liÃ©es Ã  des fichiers manquants, voici les Ã©tapes Ã  suivre :

1. **CrÃ©er un dossier `model_deep_fine`** contenant le fichier `best_bert_classifier.pt` :  
   ğŸ”— [Lien Google Drive](https://drive.google.com/drive/u/0/folders/17bf1eKwtQ_8FahoiZuCpoY9tj4WS-8xO)

2. **Dans le dossier `treatment/`, crÃ©er un sous-dossier `best_model/`** contenant les fichiers suivants :  
   - `config.json`  
   - `model.safetensors`  
   ğŸ”— [Lien Google Drive](https://drive.google.com/drive/u/0/folders/1O-D2xAY7Azgqc13bISA-0vwDjYi6Oigo)

3. **TÃ©lÃ©charger le fichier `finetuning.csv`** (dataset nettoyÃ©) :  
   ğŸ”— [Lien Google Drive](https://drive.google.com/drive/u/0/folders/1RE-AoqLj37QvteUobdxvcBbecaNkn4Tg)