# NLP - Analyse de Sentiments

## Objectif

DÃ©velopper un systÃ¨me de **classification des sentiments** Ã  partir de **posts issus des rÃ©seaux sociaux**, en utilisant des **modÃ¨les NLP** basÃ©s sur BERT.

L'objectif est de dÃ©terminer si un post est :
- **Positif** : opinion favorable, joie ou satisfaction.
- **NÃ©gatif** : critique, insatisfaction ou Ã©motion dÃ©sagrÃ©able.

---

## Dataset

Nous utilisons le dataset **[Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140)** :
- **1,6 million de tweets annotÃ©s** selon leur polaritÃ© (positif ou nÃ©gatif)

### Installation des donnÃ©es

1. TÃ©lÃ©charger le dataset depuis Kaggle.
2. Le renommer en `finetuning.csv`.
3. ExÃ©cuter le script de prÃ©paration des donnÃ©es :

   ```bash
   python datapreparation.py
   ```

Ce script effectue :
- Nettoyage des tweets (URLs, mentions, hashtagsâ€¦)
- Division des donnÃ©es en jeu d'entraÃ®nement, de validation et de test

---

## ModÃ¨les entraÃ®nÃ©s

### 1. `distilbert-base-uncased-finetuned-sst-2-english`
- ModÃ¨le prÃ©-entraÃ®nÃ© HuggingFace, fine-tunÃ© sur SST-2
- ExÃ©cution sur les donnÃ©es de test :

  ```bash
  python finetuned.py
  ```
- **Accuracy obtenue : 72%**

### 2. `bert-base-uncased` + MLP personnalisÃ©
- Ajout de 3 couches fully-connected aprÃ¨s BERT (`BertClassifier`)
- Pour entraÃ®ner le modÃ¨le :

  ```bash
  python deeptuning.py
  ```
- Pour Ã©valuer sur les donnÃ©es de test :

  ```bash
  python resultdeeptuning.py
  ```
- **Accuracy obtenue : 78%**

### 3. `distilbert-base-uncased` + couche linÃ©aire
- Fine-tuning de DistilBERT avec une couche Linear Ã  2 sorties
- Meilleure performance globale
- EntraÃ®nement :

  ```bash
  python finetuning.py
  ```
- Le modÃ¨le est sauvegardÃ© dans le dossier `treatment/`.
- Ã‰valuation :

  ```bash
  python resultfinetuning.py
  ```
- **Accuracy obtenue : 82%**

---

## Scraping & Analyse Reddit

Pour scraper des publications Reddit et les analyser avec le modÃ¨le DistilBERT :

```bash
docker compose up -d --build
```

Cela lance un environnement Docker qui :
- Scrape les posts via l'API Reddit
- Filtre les contenus en anglais
- PrÃ©dit le sentiment de chaque post

---

## Structure du projet

```text
â”œâ”€â”€ datapreparation.py
â”œâ”€â”€ model_deep_fine/
â”‚   â””â”€â”€ best_bert_classifier.pt
â”œâ”€â”€ deeptuning.py
â”œâ”€â”€ resultdeeptuning.py
â”œâ”€â”€ finetuning.py
â”œâ”€â”€ resultfinetuning.py
â”œâ”€â”€ finetuned.py
â”œâ”€â”€ treatment/
â”‚   â”œâ”€â”€ best_model.pt
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ script.py
â”œâ”€â”€ finetuning.csv
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## Technologies utilisÃ©es

- Python 3.10
- PyTorch
- HuggingFace Transformers
- scikit-learn
- pandas, numpy, tqdm
- Docker

---

## ğŸ’¡ DÃ©pannage : Fichiers manquants

Si vous rencontrez des erreurs liÃ©es Ã  des fichiers manquants, suivez ces Ã©tapes :

1. **CrÃ©er un dossier `model_deep_fine`** contenant le fichier `best_bert_classifier.pt` :  
   [Lien Google Drive](https://drive.google.com/drive/u/0/folders/17bf1eKwtQ_8FahoiZuCpoY9tj4WS-8xO)

2. **Dans le dossier `treatment/`, crÃ©er un sous-dossier `best_model/`** contenant :
   - `config.json`
   - `model.safetensors`
   [Lien Google Drive](https://drive.google.com/drive/u/0/folders/1O-D2xAY7Azgqc13bISA-0vwDjYi6Oigo)

3. **TÃ©lÃ©charger le fichier `finetuning.csv`** (dataset nettoyÃ©) :  
   [Lien Google Drive](https://drive.google.com/drive/u/0/folders/1RE-AoqLj37QvteUobdxvcBbecaNkn4Tg)